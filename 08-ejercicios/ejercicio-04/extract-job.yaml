apiVersion: batch/v1
kind: CronJob
metadata:
  name: extract-data
  namespace: ex-pipeline
spec:
  schedule: "*/10 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: extract
            image: python:3.9
            command: ["/bin/bash", "-c"]
            args:
            - >
              pip install pandas requests &&
              python -c '
              import pandas as pd
              import requests
              import os
              import time
              from datetime import datetime
              
              # Simular extracción de API
              print("Iniciando extracción de datos...")
              
              # Crear directorio si no existe
              os.makedirs("/data/raw", exist_ok=True)
              
              # Obtener datos de ejemplo (simulados)
              data = {
                  "id": list(range(1, 11)),
                  "nombre": ["Producto " + str(i) for i in range(1, 11)],
                  "precio": [i * 10.5 for i in range(1, 11)],
                  "categoria": ["A" if i % 2 == 0 else "B" for i in range(1, 11)],
                  "fecha": [datetime.now().strftime("%Y-%m-%d")] * 10
              }
              
              # Crear DataFrame
              df = pd.DataFrame(data)
              
              # Guardar datos en formato CSV
              timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
              output_file = f"/data/raw/datos_{timestamp}.csv"
              df.to_csv(output_file, index=False)
              
              print(f"Datos extraídos y guardados en {output_file}")
              '
            volumeMounts:
            - name: data-volume
              mountPath: /data
          restartPolicy: OnFailure
          volumes:
          - name: data-volume
            persistentVolumeClaim:
              claimName: etl-data 